{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prob140 import *\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "from scipy import special\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Your homeworks have two components: a written portion and a portion that also involves code.  Written work should be completed on paper, and coding questions should be done in the notebook.  You are welcome to LaTeX your answers to the written portions, but staff will not be able to assist you with LaTeX related issues. It is your responsibility to ensure that both components of the homework are submitted completely and properly to Gradescope. Refer to the bottom of the notebook for submission instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Do Your Homework ###\n",
    "The point of homework is for you to try your hand at using what you've learned in class. The steps to follow:\n",
    "\n",
    "- Go to lecture and sections, and also go over the relevant text sections before starting on the homework. This will remind you what was covered in class, and the text will typically contain examples not covered in lecture. The weekly Preparation Guide will list what you should read.\n",
    "- Work on some of the practice problems before starting on the homework.\n",
    "- Attempt the homework problems by yourself with the text, section work, and practice materials all at hand. Sometimes the week's lab will help as well. The two steps above will help this step go faster and be more fruitful.\n",
    "- At this point, seek help if you need it. Don't ask how to do the problem — ask how to get started, or for a nudge to get you past where you are stuck.\n",
    "- For a good measure of your understanding, keep track of the fraction of the homework you can do by yourself or with minimal help. It's a better measure than your homework score, and only you can measure it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules for Homework ###\n",
    "- Every answer should contain a calculation or reasoning. For example, a calculation such as $(1/3)(0.8) + (2/3)(0.7)$ or `sum([(1/3)*0.8, (2/3)*0.7])`is fine without further explanation or simplification. If we want you to simplify, we'll ask you to. But just ${5 \\choose 2}$ by itself is not fine; write \"we want any 2 out of the 5 frogs and they can appear in any order\" or whatever reasoning you used. Reasoning can be brief and abbreviated, e.g. \"product rule\" or \"not mutually excl.\"\n",
    "- You may consult others (see \"How to Do Your Homework\" above) but you must write up your own answers using your own words, notation, and sequence of steps.\n",
    "- We'll be using Gradescope. You must submit the homework according to the instructions in at the end of homework set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First Repeat ###\n",
    "Suppose you roll a die rolled repeatedly. Remember that in this class, dice are assumed fair unless the description says otherwise.\n",
    "\n",
    "For $k = 1, 2, 3, \\ldots, 6 $ let $D_k$ be the event that the first $k$ rolls all show different faces. \n",
    "\n",
    "**a)** For $k = 1, 2, 3, \\ldots, 6 $ let $D_k$ be the event that the first $k$ rolls all show different faces. Note that $P(D_1) = 0$ because you can't have different faces with just one roll.\n",
    "\n",
    "Without doing any calculations, draw a Venn diagram that shows the events $D_4$ and $D_5$. Make it clear which is which, and justify your answer. Then enter one of the symbols $\\le$, $=$, and $\\ge$ in the blank below.\n",
    "\n",
    "$P(D_5) ~ \\underline{~~~~~~~~~~} P(D_4)$\n",
    "\n",
    "**b)** For $k = 2, 3, \\ldots, 7$ let $F_k$ be the event that the $k$th roll is the first time you see a face that has already appeared. Write the event $F_k$ in terms of the events $D_1, D_2, \\ldots, D_6$.\n",
    "\n",
    "\n",
    "\n",
    "**c)** In the Venn diagram that you drew in Part **a**, there's a region that corresponds to one of the events $F_i$ for some $i$.  Say which $i$ it is, and shade that event $F_i$ in your diagram. There's no need to draw a new diagram. Just shade the appropriate region in the diagram you already drew.\n",
    "\n",
    "**d)** Thus far, you haven't used any fractions – just logic. Now for some calculation. In the code cell below, define a function `prob_D` that takes $k$ as its argument and returns $P(D_k)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student\n",
    "def prob_D(k):\n",
    "    rolls = np.arange(k)\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "def prob_D(k):\n",
    "    rolls = np.arange(k)\n",
    "    return np.prod( (6 - rolls) / 6 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to make sure that it is consistent with your answer to Part **a**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student\n",
    "prob_D(4), prob_D(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2777777777777778, 0.09259259259259259)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solution\n",
    "prob_D(4), prob_D(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** In the code cell below, define a function `prob_F` that takes $k$ as its argument and returns $P(F_k)$. Use your function `prob_D` in your definition. \n",
    "\n",
    "Then use `apply` to complete the table `first_repeat`. Its first column contains $k$ and its second column should contain $P(F_k)$. For a reminder of the use of `apply`, see the definition of the array `different` in [Section 1.4](http://prob140.org/textbook/chapters/Chapter_01/04_Birthday_Problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student\n",
    "first_repeat = Table().with_column('k', np.arange(2, 8))\n",
    "\n",
    "def prob_F(k):\n",
    "    return ...\n",
    "\n",
    "all_probs_F_k = ...apply...\n",
    "\n",
    "first_repeat = first_repeat.with_column('P(F_k)', all_probs_F_k)\n",
    "\n",
    "first_repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>k</th> <th>P(F_k)</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2   </td> <td>0.166667 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3   </td> <td>0.277778 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4   </td> <td>0.277778 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5   </td> <td>0.185185 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>6   </td> <td>0.0771605</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>7   </td> <td>0.0154321</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "k    | P(F_k)\n",
       "2    | 0.166667\n",
       "3    | 0.277778\n",
       "4    | 0.277778\n",
       "5    | 0.185185\n",
       "6    | 0.0771605\n",
       "7    | 0.0154321"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solution\n",
    "first_repeat = Table().with_column('k', np.arange(2, 8))\n",
    "\n",
    "def prob_F(k):\n",
    "    return prob_D(k-1) - prob_D(k)\n",
    "\n",
    "all_probs_F_k = first_repeat.apply(prob_F, 'k')\n",
    "\n",
    "first_repeat = first_repeat.with_column('P(F_k)', all_probs_F_k)\n",
    "\n",
    "first_repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** Run the cell below. If you created `all_probs_F_k` correctly, the sum should be a recognizable special value. Explain why the sum comes out that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(all_probs_F_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#solution\n",
    "\n",
    "### [Student Solution] First Repeat ###\n",
    "\n",
    "**a)** $D_5 \\subseteq D_4$ because if the first five rolls are all different then the first four had to be different. In the blank: $\\le$\n",
    "\n",
    "**b)** $F_k = D_{k-1} \\backslash D_k$\n",
    "\n",
    "**c)** $i=5$. It's the ring of points that are in $D_4$ but not in $D_5$.\n",
    "\n",
    "**e)** The first repetition has to happen somewhere in the rolls 2 through 7. Also first repetition can't happen on two different rolls, so $F_2, F_2, \\ldots, F_7$ are mutually exclusive. So the probabilities add up to 1. \n",
    "\n",
    "You can also establish this algebraically using Part **b** and the difference rule, but the solution above is more illuminating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. A Different Approximation ###\n",
    "\n",
    "At the end of [Section 1.5](http://prob140.org/textbook/chapters/Chapter_01/05_An_Exponential_Approximation) of the textbook, an approximate value of the chance of a collison in $n$ trials involving $N$ available codes is:\n",
    "\n",
    "Approximation 1:\n",
    "$$\n",
    "P(\\text{collision}) ~ \\sim ~ 1 - e^{-\\frac{n^2}{2N}}\n",
    "$$\n",
    "\n",
    "A simpler approximation that is often used is Approximation 2:\n",
    "\n",
    "$$\n",
    "P(\\text{collision}) ~ \\approx ~ \\frac{n^2}{2N}\n",
    "$$\n",
    "\n",
    "See [Wikipedia](https://en.wikipedia.org/wiki/Birthday_attack#Simple_approximation), for example, and keep in mind that their $H$ is our $N$.\n",
    "\n",
    "**a)** Derive Approximation 2 from Approximation 1. Refer to [properties of the exponential function](http://prob140.org/resources/exponential_approximations/) if you need to.\n",
    "\n",
    "**b)** As you have seen, for $N = 365$ the chance of a collision is just over 0.5 when $n = 23$. Use Approximation 2 to find an approximate value of $n$ by setting $P(\\text{collision})$ to be 0.5 and $N$ to be 365. Use the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student\n",
    "N = 365\n",
    "p_collision = 0.5\n",
    "\n",
    "\"\"\"Note: The value of n below is an approximation\"\"\"\n",
    "\n",
    "n = ...\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.1049731745428"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solution\n",
    "N = 365\n",
    "p_collision = 0.5\n",
    "\n",
    "\"\"\"Note: The value of n below is an approximation\"\"\"\n",
    "\n",
    "n = (p_collision * 2*N) ** 0.5\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** The answer to **b** is not great as an approximation to 23, but it's not terrible either. The simple approximation is a great way to get a rough sense of how many trials you need to for a specified collision probability when $N$ is too large for exact calculations. \n",
    "\n",
    "For example, suppose you use a 64-bit hash. Then there are $N = 2^{64} \\approx 1.8 \\times 10^{19}$ hash values. Use Approximation 2 to find an approximate number of trials $n$ so that the probability of a collision is about 0.25. Use the code cell below to write an expression that evaluates to the numerical value of the $n$ that you found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3037000499.97605"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solution\n",
    "(0.25 * 2 * (2 ** 64)) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#solution\n",
    "\n",
    "### [Student Solution] A Different Approximation ###\n",
    "\n",
    "**a)** Use the approximation $$e^x \\sim 1 + x$$ for small $x$. \n",
    "\n",
    "Then $e^{-\\frac{n^2}{2N}} \\sim 1 - \\frac{n^2}{2N}$, so $1 - e^{-\\frac{n^2}{2N}} \\sim 1 - (1 - \\frac{n^2}{2N}) = \\frac{n^2}{2N}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Heads in Coin Tossing ###\n",
    "This is one of the fundamental models of probability theory. Note that unless otherwise specified, coins in this course are assumed to be fair.\n",
    "\n",
    "This exercise is a series of quick observations. Before you start, look over some of the Combinatorics exercises in the [Math Prerequisites](http://prob140.org/assets/prereq_math_sp19.pdf) set.\n",
    "\n",
    "Suppose you toss a coin $n$ times and note down the sequence of heads (H) and tails (T). \n",
    "\n",
    "Fix an integer $k$ such that $0 \\le k \\le n$.\n",
    "\n",
    "**a)** In total, how many possible sequences are there? How many sequences have $k$ heads? \n",
    "\n",
    "[That means exactly $k$ heads, now and throughout the course. To answer the second question, it might help to imagine that there are $n$ empty spaces and you have to write the letter H in $k$ of them.]\n",
    "\n",
    "**b)** What is the chance that you get $k$ heads in your $n$ tosses? Why?\n",
    "\n",
    "**c)** Does your answer in **b** make sense in the cases $k=0$ and $k=n$? Explain.\n",
    "\n",
    "**d)** `SciPy` is a Python library for scientific computing. You will be using it a lot in this course. In particular, the `special` module of `SciPy` computes combinatorial terms and has been imported in this notebook. \n",
    "\n",
    "To calculate $\\binom{n}{k}$, use `special.comb(n, k)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 choose 2\n",
    "special.comb(10, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function `chance_of_heads` that takes `n` and `k` as its arguments and returns the chance of `k` heads in `n` tosses of a fair coin. Do not use any built-in `SciPy` probability functions; just use your answer to **b**.\n",
    "\n",
    "We have started the code for you. Try to ignore the fact that we have converted the integer `n` to a `float`. It won't affect `special.comb` and it will help ensure that the calculation is accurate when `n` and `k` are large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student\n",
    "def chance_of_heads(n, k):\n",
    "    \"\"\"Returns the chance of k heads in n tosses of a fair coin\"\"\"\n",
    "    n = float(n)\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "def chance_of_heads(n, k):\n",
    "    \"\"\"Returns the chance of k heads in n tosses of a fair coin\"\"\"\n",
    "    n = float(n)\n",
    "    return special.comb(n, k) / 2**n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check whether your function is working correctly, list all possible outcomes of two tosses of a coin and hence calculate P(0 heads), P(1 head), and P(2 heads). You don't have to turn this in, but make sure it agrees with the output of the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25, 0.5, 0.25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chance_of_heads(2, 0), chance_of_heads(2, 1), chance_of_heads(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** A class has 8 GSIs. Each GSI tosses a coin 20 times and notes the number of heads. Write an expression that evaluates to the chance that none of the GSIs gets exactly 10 heads. Your expression should use your function `chance_of_heads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21212249859944513"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solution\n",
    "(1 - chance_of_heads(20, 10)) ** 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#solution\n",
    "\n",
    "\n",
    "### [Student Solution] Heads in Coin Tossing ###\n",
    "\n",
    "**a)** Total $2^n$ (product rule of counting), among which $\\binom{n}{k}$ have $k$ heads. You just have to choose $k$ of the $n$ spots in which to write H; the rest are T.\n",
    "\n",
    "**b)** $\\binom{n}{k}/2^n$ because all the sequences are equally likely.\n",
    "\n",
    "**c)** $k=0$ is the event \"all tails\" and has chance $1/2^n$, which is consistent with the formula because $\\binom{n}{0} = 1$. Do $k=n$ analogously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. More Approximations ###\n",
    "While it is great to have exact formulas for probabilities, if the formulas are complicated then it can be hard to tell how big the probabilities are. So it is useful to have good approximations that have simpler forms and can quickly give us a sense of the magnitude.\n",
    "\n",
    "You have seen one such approximation already in the birthday problem. Here are two more.\n",
    "\n",
    "**a)** There is a bet for which your chance of winning is $1/M$. The chance is small because $M$ is very large, but you are stubborn and decide to bet anyway. In fact you bet over and over again, hoping for a win. Assume that the bets are independent of each other. What is the smallest number of times you have to bet so that your chance of winning at least once is at least 1/2? Explain why the answer is roughly a linear function of $M$ (when $M$ is large).\n",
    "\n",
    "**b)** In the previous exercise you found the chance of getting $m$ heads in $2m$ tosses of a coin. The chance involves some factorials, and factorials get large very quickly. *Stirling's approximation* says that for large $n$\n",
    "\n",
    "$$\n",
    "n! ~ \\sim ~ \\sqrt{2 \\pi n} \\cdot (n/e)^n\n",
    "$$\n",
    "\n",
    "where the symbol $\\sim$ is read as \"is asymptotically equivalent to\" and means that the ratio of the two sides goes to 1 as $n$ tends to $\\infty$.\n",
    "\n",
    "Let $m$ be a positive integer. Use Stirling's formula to approximate the chance of getting exactly $m$ heads in $2m$ tosses of a fair coin, and say what the limit is as $m \\to \\infty$. Later in the course we will see why this doesn't contradict the law of averages.\n",
    "\n",
    "**c)** For the number of tosses $2m = 50, 100, 150, \\ldots, 400$, compare the approximation in **b** to the exact value, as follows. The table `chance_and_approx` starts off with just two columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Tosses</th> <th>Heads</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>50    </td> <td>25   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>100   </td> <td>50   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>150   </td> <td>75   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>200   </td> <td>100  </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>250   </td> <td>125  </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>300   </td> <td>150  </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>350   </td> <td>175  </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>400   </td> <td>200  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Tosses | Heads\n",
       "50     | 25\n",
       "100    | 50\n",
       "150    | 75\n",
       "200    | 100\n",
       "250    | 125\n",
       "300    | 150\n",
       "350    | 175\n",
       "400    | 200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tosses = np.arange(50, 401, 50)\n",
    "heads = np.arange(25, 201, 25)\n",
    "chance_and_approx = Table().with_columns('Tosses', tosses,\n",
    "                                       'Heads', heads)\n",
    "chance_and_approx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment the table with a column labeled `Exact Chance` that contains the chance of $m$ heads in $2m$ tosses, and a column labeled `Approximation` that contains the approximation you found in **b**.\n",
    "\n",
    "Code tips:\n",
    "\n",
    "- Use `np.pi` for $\\pi$\n",
    "- Use `apply` to get an array of exact chances. See for example the construction of the array `different` in [Section 1.4](http://prob140.org/textbook/chapters/Chapter_01/04_Birthday_Problem) of the textbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student\n",
    "def exact_chance(m):\n",
    "    \"\"\"Returns P(m heads in 2m tosses)\"\"\"\n",
    "    return chance_of_heads(2*m, m)\n",
    "\n",
    "exact = ...          # array of exact chances\n",
    "approx = ...         # array of approximations\n",
    "\n",
    "chance_and_approx = chance_and_approx.with_columns('Exact Chance', exact,\n",
    "                                                 'Approximation', approx)\n",
    "chance_and_approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Tosses</th> <th>Heads</th> <th>Exact Chance</th> <th>Approximation</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>50    </td> <td>25   </td> <td>0.112275    </td> <td>0.112838     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>100   </td> <td>50   </td> <td>0.0795892   </td> <td>0.0797885    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>150   </td> <td>75   </td> <td>0.0650385   </td> <td>0.065147     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>200   </td> <td>100  </td> <td>0.0563485   </td> <td>0.056419     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>250   </td> <td>125  </td> <td>0.0504122   </td> <td>0.0504627    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>300   </td> <td>150  </td> <td>0.0460275   </td> <td>0.0460659    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>350   </td> <td>175  </td> <td>0.0426183   </td> <td>0.0426487    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>400   </td> <td>200  </td> <td>0.0398693   </td> <td>0.0398942    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Tosses | Heads | Exact Chance | Approximation\n",
       "50     | 25    | 0.112275     | 0.112838\n",
       "100    | 50    | 0.0795892    | 0.0797885\n",
       "150    | 75    | 0.0650385    | 0.065147\n",
       "200    | 100   | 0.0563485    | 0.056419\n",
       "250    | 125   | 0.0504122    | 0.0504627\n",
       "300    | 150   | 0.0460275    | 0.0460659\n",
       "350    | 175   | 0.0426183    | 0.0426487\n",
       "400    | 200   | 0.0398693    | 0.0398942"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solution\n",
    "def exact_chance(m):\n",
    "    \"\"\"Returns P(m heads in 2m tosses)\"\"\"\n",
    "    return chance_of_heads(2*m, m)\n",
    "\n",
    "exact = chance_and_approx.apply(exact_chance, 'Heads')\n",
    "approx = (np.pi * heads) ** -0.5\n",
    "\n",
    "chance_and_approx = chance_and_approx.with_columns('Exact Chance', exact,\n",
    "                                                 'Approximation', approx)\n",
    "chance_and_approx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a great approximation! Run the cell below for a visual comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x102233b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chance_and_approx.drop('Heads').scatter('Tosses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#solution\n",
    "\n",
    "### [Student Solution] More Approximations ###\n",
    "\n",
    "**a)** If you make $n$ bets, the chance of losing them all is $\\big{(} 1 - \\frac{1}{M} \\big{)}^n$. This is allowed to be at most 1/2. Solve the inequality $\\big{(} 1 - \\frac{1}{M} \\big{)}^n \\le \\frac{1}{2}$ by taking the log on both sides and remembering that the log of a fraction is negative. So $n \\ge \\frac{\\log(1/2)}{\\log(1 - 1/M)}$. \n",
    "\n",
    "$M$ is large, so the denominator is the log of a number close to 1. Use $\\log(1 + x) \\sim x$ for small $x$, to get that $n$ should be roughly $\\frac{\\log(1/2)}{-1/M} = M\\log(2) \\approx 0.693M$ which is linear in $M$.\n",
    "\n",
    "In ancient days, gamblers knew from experience that the answer is about 2/3 of $M$. That was some pretty impressive data science on their part, long before logarithms were developed.\n",
    "\n",
    "**b)** By the previous problem, the chance of $m$ heads in $2m$ tosses is\n",
    "$$\n",
    "\\frac{(2m)!}{m!m!} \\cdot 2^{-2m} ~ \\sim ~ \\frac{\\sqrt{2\\pi(2m)} \\cdot (2m/e)^{2m}}{2\\pi m \\cdot (m/e)^{2m}} \\cdot 2^{-2m} ~ = ~ \\frac{\\sqrt{\\pi m}}{\\pi m} ~ = ~ \\frac{1}{\\sqrt{\\pi m}} ~ \\to ~ 0 \\text{ as } m \\to \\infty\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions ##\n",
    "\n",
    "Many assignments throughout the course will have a written portion and a code portion. Please follow the directions below to properly submit both portions.\n",
    "\n",
    "### Written Portion ###\n",
    "*  Scan all the pages into a PDF. You can use any scanner or a phone using applications such as CamScanner. Please **DO NOT** simply take pictures using your phone. \n",
    "* Please start a new page for each question. If you have already written multiple questions on the same page, you can crop the image in CamScanner or fold your page over (the old-fashioned way). This helps expedite grading.\n",
    "* It is your responsibility to check that all the work on all the scanned pages is legible.\n",
    "\n",
    "### Code Portion ###\n",
    "* Save your notebook using File > Save and Checkpoint.\n",
    "* Generate a PDF file using File > Download as > PDF via LaTeX. This might take a few seconds and will automatically download a PDF version of this notebook.\n",
    "    * If you have issues, please make a follow-up post on the general HW 1 Piazza thread.\n",
    "    \n",
    "### Submitting ###\n",
    "* Combine the PDFs from the written and code portions into one PDF.  [Here](https://smallpdf.com/merge-pdf) is a useful tool for doing so. \n",
    "* Submit the assignment to Homework 1 on Gradescope. \n",
    "* **Make sure to assign each page of your pdf to the correct question.**\n",
    "* **It is your responsibility to verify that all of your work shows up in your final PDF submission.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
